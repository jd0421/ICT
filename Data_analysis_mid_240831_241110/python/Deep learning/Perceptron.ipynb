{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 간단한 멀티퍼셉트론 구현 (순전파 및 역전파)\n",
    "다음은 Python의 numpy를 사용하여 간단한 MLP를 구현한 코드입니다.\n",
    "\n",
    "### 코드 설명\n",
    "1. **활성화 함수**: Sigmoid 함수와 그 미분 함수를 정의했습니다.\n",
    "2. **손실 함수**: Mean Squared Error (MSE) 함수로 정의했습니다.\n",
    "3. **MLP 클래스**:\n",
    "   - 초기화 함수에서 가중치와 편향을 랜덤으로 초기화합니다.\n",
    "   - `forward` 메서드에서 순전파를 계산합니다.\n",
    "   - `backward` 메서드에서 역전파를 계산하여 가중치와 편향을 업데이트합니다.\n",
    "   - `train` 메서드에서 주어진 에포크 동안 학습을 수행합니다.\n",
    "4. **데이터**: XOR 문제를 해결하기 위해 입력과 출력을 정의했습니다.\n",
    "5. **훈련 및 예측**: MLP 모델을 학습시키고, 학습 후 예측을 출력합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 활성화 함수 및 그 미분 함수\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수 (Mean Squared Error)\n",
    "def mse_loss(y_true, y_pred):\n",
    "    return ((y_true - y_pred) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP 클래스 정의\n",
    "class MLP:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # 가중치 초기화\n",
    "        self.weights_input_hidden = np.random.rand(input_size, hidden_size)\n",
    "        self.bias_hidden = np.zeros((1, hidden_size))\n",
    "        self.weights_hidden_output = np.random.rand(hidden_size, output_size)\n",
    "        self.bias_output = np.zeros((1, output_size))\n",
    "\n",
    "    def forward(self, X):\n",
    "        # 순전파 계산\n",
    "        self.hidden_input = np.dot(X, self.weights_input_hidden) + self.bias_hidden\n",
    "        self.hidden_output = sigmoid(self.hidden_input)\n",
    "        self.final_input = np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_output\n",
    "        self.final_output = sigmoid(self.final_input)\n",
    "        return self.final_output\n",
    "\n",
    "    def backward(self, X, y, learning_rate):\n",
    "        # 손실의 미분 계산 (역전파)\n",
    "        output_error = y - self.final_output\n",
    "        output_delta = output_error * sigmoid_derivative(self.final_output)\n",
    "\n",
    "        hidden_error = output_delta.dot(self.weights_hidden_output.T)\n",
    "        hidden_delta = hidden_error * sigmoid_derivative(self.hidden_output)\n",
    "\n",
    "        # 가중치 및 편향 업데이트\n",
    "        self.weights_hidden_output += self.hidden_output.T.dot(output_delta) * learning_rate\n",
    "        self.bias_output += np.sum(output_delta, axis=0, keepdims=True) * learning_rate\n",
    "        self.weights_input_hidden += X.T.dot(hidden_delta) * learning_rate\n",
    "        self.bias_hidden += np.sum(hidden_delta, axis=0, keepdims=True) * learning_rate\n",
    "\n",
    "    def train(self, X, y, learning_rate, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            self.forward(X)\n",
    "            self.backward(X, y, learning_rate)\n",
    "            if epoch % 1000 == 0:\n",
    "                loss = mse_loss(y, self.final_output)\n",
    "                print(f\"Epoch {epoch}, Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.26490089531768896\n",
      "Predictions after training:\n",
      "[[0.49584349]\n",
      " [0.50723671]\n",
      " [0.50085923]\n",
      " [0.5122533 ]]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 예제 (XOR 문제)\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# MLP 모델 초기화 및 학습\n",
    "mlp = MLP(input_size=2, hidden_size=2, output_size=1)\n",
    "mlp.train(X, y, learning_rate=0.1, epochs=100) # epochs=100000\n",
    "\n",
    "# 예측\n",
    "print(\"Predictions after training:\")\n",
    "print(mlp.forward(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단층 퍼셉트론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단층 퍼셉트론의 한계와 XOR 게이트 문제\n",
    "\n",
    "1. **단층 퍼셉트론의 구현 가능 범위**:\n",
    "   - 단층 퍼셉트론은 **AND, NAND, OR 게이트** 구현 가능.\n",
    "   - **XOR 게이트는 구현 불가**.\n",
    "   \n",
    "2. **이유**:\n",
    "   - 단층 퍼셉트론은 **직선 하나로 두 영역을 분리**할 수 있는 문제만 해결 가능.\n",
    "   - XOR 게이트의 출력값 분포는 직선 하나로 나눌 수 없는 구조를 가짐.\n",
    "\n",
    "3. **시각적 이해**:\n",
    "   - **AND, NAND, OR 게이트**는 하얀색 원(출력 0)과 검은색 원(출력 1)을 직선으로 구분 가능.\n",
    "   - **XOR 게이트**는 하얀색 원과 검은색 원을 **단일 직선으로 분리 불가**; 최소 두 개의 선이 필요.\n",
    "\n",
    "4. **해결 방법: 다층 퍼셉트론**:\n",
    "   - 다층 퍼셉트론은 **여러 층의 뉴런을 사용해 비선형 분류** 가능.\n",
    "   - XOR 게이트와 같은 문제도 다층 퍼셉트론으로 해결 가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AND\n",
    "def AND(x1, x2):\n",
    "    w1,w2, theta = 0.5, 0.5, 0.7 #theta\n",
    "    tmp = x1*w1 + x2*w2\n",
    "    if tmp <= theta:\n",
    "        return 0\n",
    "    elif tmp > theta:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AND(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOT AND\n",
    "def NAND(x1, x2):\n",
    "    w1,w2, theta = -0.5, -0.5, -0.7\n",
    "    tmp = x1*w1 + x2*w2\n",
    "    if tmp <= theta:\n",
    "        return 0\n",
    "    elif tmp > theta:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAND(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OR\n",
    "def OR(x1, x2):\n",
    "    x = np.array([x1, x2])\n",
    "    w = np.array([0.5, 0.5]) # AND와는 가중치(w와 b)만 다르다.\n",
    "    b = -0.2\n",
    "    tmp = np.sum(w*x) + b\n",
    "    if tmp <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OR(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOR \n",
    "def NOR(x1, x2):\n",
    "    x = np.array([x1, x2])\n",
    "    w = np.array([0.5, 0.5]) # AND와는 가중치(w와 b)만 다르다.\n",
    "    b = -0.2\n",
    "    tmp = np.sum(w*x) + b\n",
    "    if tmp <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## XOR\n",
    "## - XOR문제가 해결이 안됨!\n",
    "## - 단층 퍼셉트론으로 해결 안되는 문제를 두층을 쌓아서 해결\n",
    "\n",
    "def XOR(x1,x2):\n",
    "    s1 = NAND(x1,x2)\n",
    "    s2 = OR(x1,x2)\n",
    "    y = AND(s1,s2)\n",
    "    return y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
